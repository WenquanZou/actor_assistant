{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WenquanZou/actor_assistant/blob/BERT_example/demo_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tJB2B8bUav2F"
   },
   "source": [
    "# Library installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "colab_type": "code",
    "id": "KCqM6ypNjctp",
    "outputId": "f6ab13f6-be32-4cd6-edde-12e974d7bf9d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ry9DPQJaktd"
   },
   "source": [
    "#2 Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTpelwBifGdX"
   },
   "source": [
    "## 2.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ty16nmRfaL9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Download data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xugHvJEofHKo"
   },
   "source": [
    "## 2.2 Parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktHGdCAIe_ju",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# An example of parsing raw input into BERT acceptable input\n",
    "# TODO: Parse data\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "# An example of BERT input\n",
    "text_dataset = [\"After stealing money from the bank vault, the bank robber was seen \" \\\n",
    "       \"fishing on the Mississippi river bank.\"]\n",
    "\n",
    "inputs = [tokenizer.encode_plus(text_input, add_special_tokens = True, pad_to_max_length=True) for text_input in text_dataset]\n",
    "\n",
    "input_ids = [d['input_ids'] for d in inputs]\n",
    "input_segments = [d['token_type_ids'] for d in inputs]\n",
    "# input_attention_masks = [d['attention_mask'] for d in inputs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3tZn79Pfht4"
   },
   "source": [
    "# 3 Implementation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_bUN_tIaTs5U",
    "outputId": "c2f26eb0-26fe-445f-9828-717f05759134",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor(input_ids)\n",
    "segments_tensor = torch.tensor(input_segments)\n",
    "# attention_masks_tensor = torch.tensor(input_attention_masks)\n",
    "\n",
    "# # Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "# # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "Xyus7BjzNGNU",
    "outputId": "65e8e811-c8fd-49de-f078-4e33c4057637",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4GNP9gYawPi"
   },
   "source": [
    "# 4 Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvZyNC-Rq5bd"
   },
   "source": [
    "# 5 Model output\n",
    "BERT model output a feature can be learn for later fine-tuning, which has (512, 768) dimension for just one sentence embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "3KJCoozkTwDh",
    "outputId": "8ce12d50-a64c-49ae-a04f-69a2ac413364",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    last_hidden_states,_ = model(tokens_tensor, segments_tensor)\n",
    "\n",
    "print(f\"The shape of feature {last_hidden_states.shape} \")\n",
    "\n",
    "\n",
    "print(last_hidden_states)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "demo_BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
